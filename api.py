import numpy as np
import pandas as pd
import joblib
from tensorflow import keras
from fastapi import FastAPI
from pydantic import BaseModel
import os
import uvicorn
import logging
from fastapi.responses import JSONResponse

# ====== Cháº¡y TensorFlow trÃªn CPU ======
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

# ====== Cáº¥u hÃ¬nh logging ======
logging.basicConfig(level=logging.INFO)

# ====== Khá»Ÿi táº¡o FastAPI ======
app = FastAPI()

# ====== Táº£i láº¡i mÃ´ hÃ¬nh vÃ  scaler ======
def load_model_and_scaler():
    try:
        model = keras.models.load_model('model_land.h5', compile=False)
        model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
        logging.info("âœ… MÃ´ hÃ¬nh Ä‘Ã£ táº£i thÃ nh cÃ´ng!")
    except Exception as e:
        logging.error(f"âŒ Lá»—i khi táº£i mÃ´ hÃ¬nh: {e}")
        model = None

    try:
        scaler = joblib.load('scaler.pkl')  # Load scaler Ä‘Ã£ lÆ°u
        logging.info("âœ… Scaler Ä‘Ã£ táº£i thÃ nh cÃ´ng!")
    except Exception as e:
        logging.error(f"âŒ Lá»—i khi táº£i scaler: {e}")
        scaler = None

    return model, scaler

# Táº£i mÃ´ hÃ¬nh vÃ  scaler khi khá»Ÿi Ä‘á»™ng API
model, scaler = load_model_and_scaler()

# ====== Äá»‹nh nghÄ©a kiá»ƒu dá»¯ liá»‡u Ä‘áº§u vÃ o ======
class InputData(BaseModel):
    features: list

# ====== Chuyá»ƒn Ä‘á»•i FS thÃ nh nhÃ£n ======
def classify_fs(fs_value):
    """ Quy Ä‘á»•i há»‡ sá»‘ an toÃ n thÃ nh nhÃ£n """
    if fs_value >= 1.5:
        return "âœ… An toÃ n"
    elif 1.0 <= fs_value < 1.5:
        return "âš ï¸ Cáº§n kiá»ƒm tra"
    else:
        return "âŒ Nguy hiá»ƒm"

# ====== API Endpoint Ä‘á»ƒ dá»± Ä‘oÃ¡n ======
@app.post("/predict")
async def predict(data: InputData):
    """ API nháº­n dá»¯ liá»‡u, chuáº©n hÃ³a vÃ  tráº£ vá» há»‡ sá»‘ an toÃ n FS """
    logging.info(f"ğŸ“© Nháº­n dá»¯ liá»‡u Ä‘áº§u vÃ o: {data.features}")

    try:
        # Kiá»ƒm tra náº¿u model hoáº·c scaler khÃ´ng táº£i Ä‘Æ°á»£c
        if model is None or scaler is None:
            return JSONResponse(content={"error": "MÃ´ hÃ¬nh hoáº·c scaler chÆ°a Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng."}, status_code=500)

        # Kiá»ƒm tra dá»¯ liá»‡u Ä‘áº§u vÃ o
        if not isinstance(data.features, list) or len(data.features) != 7:
            return JSONResponse(content={"error": "Dá»¯ liá»‡u Ä‘áº§u vÃ o khÃ´ng há»£p lá»‡. Cáº§n Ä‘Ãºng 7 giÃ¡ trá»‹!"}, status_code=400)

        # Chuyá»ƒn dá»¯ liá»‡u thÃ nh numpy array
        input_data = np.array(data.features).reshape(1, -1)
        columns = ['c', 'l', 'gamma', 'h', 'u', 'phi', 'beta']
        input_data_df = pd.DataFrame(input_data, columns=columns)

        # Chuáº©n hÃ³a dá»¯ liá»‡u vá»›i scaler Ä‘Ã£ lÆ°u
        try:
            input_data_scaled = scaler.transform(input_data_df)
        except Exception as e:
            return JSONResponse(content={"error": f"Lá»—i khi chuáº©n hÃ³a dá»¯ liá»‡u: {str(e)}"}, status_code=500)

        # Dá»± Ä‘oÃ¡n há»‡ sá»‘ an toÃ n
        try:
            predicted_fs = model.predict(input_data_scaled)[0][0]
        except Exception as e:
            return JSONResponse(content={"error": f"Lá»—i khi dá»± Ä‘oÃ¡n há»‡ sá»‘ an toÃ n: {str(e)}"}, status_code=500)

        # Chuyá»ƒn Ä‘á»•i FS thÃ nh nhÃ£n
        fs_label = classify_fs(predicted_fs)

        logging.info(f"ğŸ”® Dá»± Ä‘oÃ¡n FS: {predicted_fs} - {fs_label}")

        return JSONResponse(content={"FS": round(predicted_fs, 3), "Conclusion": fs_label}, status_code=200)

    except Exception as e:
        return JSONResponse(content={"error": f"Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {str(e)}"}, status_code=500)

# ====== Endpoint kiá»ƒm tra API Ä‘ang cháº¡y ======
@app.get("/")
def home():
    return JSONResponse(content={"message": "API FS Model is running!"}, status_code=200)

# ====== Cháº¡y API trÃªn cá»•ng Render ======
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))  # Render yÃªu cáº§u láº¥y cá»•ng tá»« biáº¿n mÃ´i trÆ°á»ng
    uvicorn.run(app, host="0.0.0.0", port=port, timeout_keep_alive=120)
